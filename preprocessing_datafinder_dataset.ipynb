{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import re \n",
    "from re import split\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./datafinder/datafinder_dataset/train_data.jsonl', lines=True)\n",
    "\n",
    "df_dataset_information = pd.read_json('./datafinder/datafinder_dataset/dataset_search_collection.jsonl', lines=True)\n",
    "df.drop_duplicates(subset=['paper_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = (\n",
    "    r'\\\\\\(.*?\\\\\\)|'  # LaTeX inline math (\\(...\\))\n",
    "    r'\\r\\n|'  # Line breaks\n",
    "    r'\\*\\*|'  # Asterisks\n",
    "    r'\\$.*?\\$|'  # LaTeX inline math ($...$)\n",
    "    r'\\\\\\[.*?\\\\\\]|'  # LaTeX display math (\\[...\\])\n",
    "    r'https?://\\S+|'  # URLs starting with http:// or https://\n",
    "    r'www\\.\\S+|'  # URLs starting with www.\n",
    "    r'ftp://\\S+|'  # URLs starting with ftp://\n",
    "    r'\\\\begin\\{equation\\}.*?\\\\end\\{equation\\}|'  # LaTeX display math (\\begin{equation}...\\end{equation})\n",
    "    r'\\\\[a-zA-Z]+\\*?(?:\\[[^\\]]*\\])?(?:\\{[^}]*\\})?|' # LaTeX commands\n",
    "    r'\\\\langle.*?\\\\rangle|'  # LaTeX angle brackets (\\langle...\\rangle)\n",
    "    r'https?://[^\\s]+(?:[\\s\\.,]|$)|'  # Match http or https URLs, followed by space, dot, or end of string\n",
    "    r'www\\.[^\\s]+(?:[\\s\\.,]|$)'  # Match URLs starting with www., followed by space, dot, or end of string\n",
    "    r'\\[Image Source\\: \\[.*?\\]|'\n",
    "    r'\\(Image Source\\: \\[|'\n",
    "    r'\\[Image Source\\: \\[|'\n",
    "    r'\\(Source\\: \\[.*?\\]|'\n",
    "    r'Source\\: \\[|'  \n",
    "    r'\\(\\s*/paper/[^)]+\\s*\\)'\n",
    "    \n",
    ")  \n",
    "\n",
    "df['abstract'] = df['abstract'].apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "# df_dataset_information['contents'] = df_dataset_information['contents'].apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "df_graph = df[['paper_id', 'outbound_citations', 'positives', 'negatives']]\n",
    "\n",
    "df_paper = df[['title', 'abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17397\n"
     ]
    }
   ],
   "source": [
    "pprIdx = {paper_id: idx for idx, paper_id in enumerate(df['paper_id'])}\n",
    "\n",
    "print(len(pprIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CIFAR-10': 0, 'ImageNet': 1, 'CAT2000': 2, 'Hopkins155': 3, 'VRD': 4, 'Middlebury': 5, 'KITTI': 6, 'LAMA': 7, 'COCO': 8, 'Jester': 9, 'JFLEG': 10, 'IAM': 11, 'Set5': 12, 'AFW': 13, 'FRGC': 14, 'WikiBio': 15, 'Cora': 16, 'BSDS500': 17, 'MovieLens': 18, 'COMA': 19, 'UCF101': 20, 'CARLA': 21, 'Birdsnap': 22, 'PACS': 23, 'VCR': 24, 'ARC': 25, 'MultiRC': 26, 'AudioSet': 27, 'Flickr30k': 28, 'CelebA': 29, 'MuJoCo': 30, 'ReferItGame': 31, 'WebText': 32, 'WikiText-103': 33, 'DeepFashion': 34, 'DRCD': 35, 'NewsQA': 36, 'SQuAD': 37, 'WN18': 38, 'AFLW': 39, 'Helen': 40, 'SumMe': 41, 'Django': 42, 'CompCars': 43, 'ETH': 44, 'Caltech-101': 45, 'LFPW': 46, 'Cityscapes': 47, 'RaFD': 48, 'ECSSD': 49, 'SimpleQuestions': 50, 'QNLI': 51, 'MRPC': 52, 'RACE': 53, 'GLUE': 54, 'SNLI': 55, 'DRIVE': 56, 'ShapeNet': 57, 'MultiNLI': 58, 'DAQUAR': 59, 'IEMOCAP': 60, 'VIPeR': 61, 'STARE': 62, 'ShanghaiTech': 63, 'Pix3D': 64, 'CAD-120': 65, 'HandNet': 66, 'CoQA': 67, 'HMDB51': 68, 'FaceForensics': 69, 'DAVIS': 70, 'ActivityNet': 71, 'BioGRID': 72, 'DBpedia': 73, 'ZINC': 74, 'TriviaQA': 75, 'MPII': 76, 'VizDoom': 77, 'ESC-50': 78, 'ORL': 79, 'McMaster': 80, 'DTD': 81, 'SYNTHIA': 82, 'ModelNet': 83, 'SST': 84, 'Mall': 85, 'MARS': 86, 'AffectNet': 87, 'Penn Treebank': 88, 'OTB': 89, 'Breakfast': 90, 'HyperLex': 91, 'SearchQA': 92, 'Universal Dependencies': 93, 'SUNCG': 94, 'ELI5': 95, 'WikiSum': 96, 'KTH': 97, 'MovieQA': 98, 'COFW': 99, 'WebQuestions': 100, 'Market-1501': 101, 'LaSOT': 102, 'VOT2017': 103, 'SEMAINE': 104, 'Oxford5k': 105, 'Adience': 106, '3DPW': 107, 'MORPH': 108, 'MMI': 109, 'JAFFE': 110, 'FBMS': 111, 'FLIC': 112, 'Places': 113, 'SNIPS': 114, 'DBLP': 115, 'nuScenes': 116, 'ICDAR 2013': 117, 'LSP': 118, 'VehicleID': 119, 'CUHK03': 120, 'CLEVR': 121, 'Epinions': 122, 'DAVIS 2016': 123, 'CASIA-WebFace': 124, 'MegaFace': 125, 'DailyDialog': 126, 'CK+': 127, 'Citeseer': 128, 'USPS': 129, 'MPQA Opinion Corpus': 130, 'SALICON': 131, 'GTEA': 132, 'VoxCeleb2': 133, 'LUNA': 134, 'WikiQA': 135, 'DICM': 136, 'DukeMTMC-reID': 137, 'Letter': 138, 'Poser': 139, 'Wireframe': 140, 'SBD': 141, 'SICK': 142, 'USF': 143, 'BC5CDR': 144, 'FewRel': 145, 'FFHQ': 146, 'WikiTableQuestions': 147, 'Charades': 148, 'ScanNet': 149, 'HIC': 150, 'aPY': 151, 'Polyvore': 152, 'PETA': 153, 'ObjectNet': 154, 'WikiHow': 155, 'MSRC-12': 156, 'LFSD': 157, 'HolStep': 158, 'ENZYMES': 159, 'PROTEINS': 160, 'Matterport3D': 161, 'ConceptNet': 162, 'Pinterest': 163, 'LSUN': 164, 'FB15k': 165, 'Foursquare': 166, 'SentEval': 167, 'JHMDB': 168, 'MSVD': 169, 'LSMDC': 170, 'MELD': 171, '300W': 172, 'AwA': 173, 'VOT2016': 174, 'PartNet': 175, 'YouTube-8M': 176, 'NarrativeQA': 177, 'VOT2018': 178, 'Reddit': 179, 'CheXpert': 180, 'RESISC45': 181, 'LIP': 182, 'BookCorpus': 183, 'NABirds': 184, 'DAVIS 2017': 185, 'GTA5': 186, 'RAP': 187, 'FaceWarehouse': 188, 'iNaturalist': 189, 'E2E': 190, 'MultiWOZ': 191, 'BP4D': 192, 'CINIC-10': 193, 'LRW': 194, 'KP20k': 195, 'Ciao': 196, 'Chairs': 197, 'Cholec80': 198, 'OpenBookQA': 199, 'SWAG': 200, 'CommonsenseQA': 201, 'HRF': 202, 'PPMI': 203, 'Food-101': 204, 'CityPersons': 205, 'SUN360': 206, 'How2': 207, 'MemeTracker': 208, 'FER2013': 209, 'MCTest': 210, 'MCScript': 211, 'LVIS': 212, 'FEVER': 213, 'SFEW': 214, 'FER+': 215, 'DUTS': 216, 'PoseTrack': 217, 'WikiLarge': 218, 'AVA': 219, 'CADP': 220, 'DDI': 221, 'DISFA': 222, 'TotalCapture': 223, 'VizWiz': 224, 'AMASS': 225, 'Event2Mind': 226, 'BioASQ': 227, 'NLPR': 228, 'AOLP': 229, 'SceneNN': 230, 'NCLT': 231, 'LRS3-TED': 232, 'HOList': 233, 'SHREC': 234, 'UCY': 235, 'PanoContext': 236, 'Arcade Learning Environment': 237, 'FMA': 238, 'CHiME-5': 239, 'WikiSQL': 240, 'FG-NET': 241, 'MOTChallenge': 242, 'LOCATA': 243, 'GYAFC': 244, 'WiderPerson': 245, 'UBIRIS.v2': 246, 'TrackingNet': 247, 'COLLAB': 248, 'HotpotQA': 249, 'ISTD': 250, 'AVD': 251, 'SUN3D': 252, 'PASCAL3D+': 253, 'WebVision': 254, 'CrowdHuman': 255, 'Visual7W': 256, 'LaMem': 257, 'iKala': 258, 'CBT': 259, 'CARPK': 260, 'Sketch': 261, 'Urban100': 262, 'R2R': 263, 'UTKFace': 264, 'LRS2': 265, 'MSRDailyActivity3D': 266, 'HICO': 267, 'WebNLG': 268, 'LOL': 269, 'EmoryNLP': 270, 'DiscoFuse': 271, 'VeRi-776': 272, 'EuroSAT': 273, 'BigEarthNet': 274, 'DIRHA': 275, 'CULane': 276, 'GoPro': 277, 'Kvasir': 278, 'AMiner': 279, 'MusicNet': 280, 'LAMBADA': 281, 'Scan2CAD': 282, 'DuReader': 283, 'CoLA': 284, 'CodeSearchNet': 285, 'NEWSROOM': 286, 'WikiText-2': 287, 'THCHS-30': 288, 'SEED': 289, 'AVSD': 290, 'DiDeMo': 291, 'SIXray': 292, 'BIOSSES': 293, 'Volleyball': 294, 'EgoHands': 295, 'ConvAI2': 296, 'WikiHop': 297, 'Tatoeba': 298, 'Set11': 299, 'M4': 300, 'Set12': 301, 'DocRED': 302, 'CACD': 303, 'MUSE': 304, 'TDIUC': 305, 'LibriSpeech': 306, 'EYEDIAP': 307, 'OmniArt': 308, 'Dayton': 309, 'DeepScores': 310, '4DFAB': 311, 'Semantic3D': 312, 'WFLW': 313, 'AI2D': 314, 'MAFL': 315, 'Sprites': 316, 'VCTK': 317, 'MOT16': 318, 'MOT15': 319, 'AIDS': 320, 'Argoverse': 321, 'EgoGesture': 322, 'MegaDepth': 323, 'MultiTHUMOS': 324, 'YAGO': 325, 'Pubmed': 326, 'Panlex': 327, 'NSynth': 328, 'NYUv2': 329, 'MetaQA': 330, 'GOT-10k': 331, 'DOTA': 332, 'QUASAR-T': 333, 'HoME': 334, 'QASC': 335, 'SciERC': 336, 'BUFF': 337, 'Florence': 338, 'BeerAdvocate': 339, 'WikiConv': 340, 'WikiReading': 341, 'MAESTRO': 342, 'iPinYou': 343, 'HappyDB': 344, 'EVALution': 345, 'MLDoc': 346, 'ASTD': 347, 'RotoWire': 348, 'ITOP': 349, 'AI2-THOR': 350, 'IQUAD': 351, 'Mindboggle': 352, 'PGM': 353, 'EMOTIC': 354, '3DMatch': 355, 'VQG': 356, 'Gowalla': 357, 'TVQA': 358, 'YouCook2': 359, 'PISC': 360, 'PCam': 361, 'CORe50': 362, 'DomainNet': 363, 'OpenEDS': 364, 'XNLI': 365, 'DROP': 366, 'OpenSubtitles': 367, 'Raider': 368, 'Manga109': 369, 'WikiMovies': 370, 'FreiHAND': 371, 'xView': 372, 'NAB': 373, 'SUN09': 374, 'MOT17': 375, 'DVQA': 376, 'DIV2K': 377, 'MuPoTS-3D': 378, 'G3D': 379, 'NCI1': 380, 'Human3.6M': 381, 'CATER': 382, 'WikiArt': 383, 'VisDA-2017': 384, 'SQA': 385, 'Florentine': 386, 'SCAN': 387, 'Sim10k': 388, 'RoboCup': 389, 'OCHuman': 390, 'AQA-7': 391, 'CHASE_DB1': 392, 'Comic2k': 393, 'FERG': 394, 'VATEX': 395, 'MINC': 396, 'XSum': 397, 'MTNT': 398, 'DeepLoc': 399, 'COWC': 400, 'EmotionLines': 401, 'FC100': 402, 'SciCite': 403, 'SKU110K': 404, 'fMoW': 405, 'iSUN': 406, 'CrowdPose': 407, 'CIHP': 408, 'ScribbleSup': 409, 'ATOMIC': 410, 'CliCR': 411, 'COIN': 412, 'LIAR': 413, 'OLID': 414, 'TrajNet': 415, '3DFAW': 416, 'VegFru': 417, 'Oxford105k': 418, 'VIST': 419, 'HindEnCorp': 420, 'DREAM': 421, 'AIRS': 422, 'FSS-1000': 423, 'TGIF': 424, 'ListOps': 425, 'AISHELL-1': 426, 'WMCA': 427, 'RSICD': 428, 'VOT2014': 429, 'LSHTC': 430, 'JFT-300M': 431, 'AADB': 432, 'WinoBias': 433, 'FDDB': 434, 'ROPES': 435, 'PeerRead': 436, 'ADE20K': 437, 'decaNLP': 438, 'CQR': 439, 'JW300': 440, 'RecipeQA': 441, 'MURA': 442, 'A2D': 443, 'CAL500': 444, 'MineRL': 445, 'CrowdFlow': 446, 'CONVERSE': 447, 'EMBER': 448, 'PIRM': 449, 'SALSA': 450, 'CLINC150': 451, 'TableBank': 452, 'K2HPD': 453, 'Sports-1M': 454, 'PAWS': 455, 'WildDash': 456, 'Video2GIF': 457, 'FigureQA': 458, 'PHM2017': 459, 'ContactDB': 460}\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "dataset_to_label = {} #for all dataset in the train data\n",
    "label_counter = 0\n",
    "\n",
    "for datasets in df_graph['positives']:\n",
    "    for dataset in datasets:\n",
    "        if dataset not in dataset_to_label:\n",
    "            dataset_to_label[dataset] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "print(dataset_to_label)\n",
    "print(label_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dataset_target_id dataset_name  \\\n",
      "0                    0     CIFAR-10   \n",
      "1                    1     ImageNet   \n",
      "2                    2      CAT2000   \n",
      "3                    3   Hopkins155   \n",
      "4                    4          VRD   \n",
      "..                 ...          ...   \n",
      "456                456     WildDash   \n",
      "457                457    Video2GIF   \n",
      "458                458     FigureQA   \n",
      "459                459      PHM2017   \n",
      "460                460    ContactDB   \n",
      "\n",
      "                                       dataset_content  \n",
      "0    The **CIFAR-10** dataset (Canadian Institute f...  \n",
      "1    The **ImageNet** dataset contains 14,197,122 a...  \n",
      "2    Includes 4000 images; 200 from each of 20 cate...  \n",
      "3    The Hopkins 155 dataset consists of 156 video ...  \n",
      "4    The Visual Relationship Dataset (**VRD**) cont...  \n",
      "..                                                 ...  \n",
      "456  WildDash is a benchmark evaluation method is p...  \n",
      "457  The **Video2GIF** dataset contains over 100,00...  \n",
      "458  FigureQA is a visual reasoning corpus of over ...  \n",
      "459  PHM2017 is a new dataset consisting of 7,192 E...  \n",
      "460  **ContactDB** is a dataset of contact maps for...  \n",
      "\n",
      "[461 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_idcontent_all = []\n",
    "\n",
    "for _, row in df_dataset_information.iterrows():\n",
    "    dataset_name = row['id']\n",
    "    dataset_content = row['contents']\n",
    "    if dataset_name in dataset_to_label.keys():\n",
    "        dataset_target_id = dataset_to_label[dataset_name]\n",
    "        dataset_idcontent_all.append((dataset_target_id, dataset_name, dataset_content))\n",
    "\n",
    "df_dataset_idcontent = pd.DataFrame(dataset_idcontent_all, columns=['dataset_target_id', 'dataset_name', 'dataset_content'])\n",
    "\n",
    "df_dataset_idcontent.sort_values(by='dataset_target_id', inplace=True, ignore_index=True)\n",
    "df_dataset_idcontent.drop_duplicates(subset=['dataset_target_id'], inplace=True, ignore_index=True)\n",
    "print(df_dataset_idcontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_dataset = (\n",
    "    r'\\\\\\(.*?\\\\\\)|'  # LaTeX inline math (\\(...\\))\n",
    "    r'\\r\\n|'  # Line breaks\n",
    "    r'\\*\\*|'  # Asterisks\n",
    "    r'\\*|'  # Asterisks\n",
    "    r'\\$.*?\\$|'  # LaTeX inline math ($...$)\n",
    "    r'\\\\\\[.*?\\\\\\]|'  # LaTeX display math (\\[...\\])\n",
    "    r'\\\\[a-zA-Z]+\\*?(?:\\[[^\\]]*\\])?(?:\\{[^}]*\\})?|' # LaTeX commands\n",
    "    r'\\n|'\n",
    "    r'\\n+|'\n",
    "\n",
    "    r'\\(https?://\\S+\\)|'  # URLs starting with http:// or https://\n",
    "    r'(Source:|Image Source:|Image:|NOTE: ).*'\n",
    "    \n",
    ")  \n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned = re.sub(pattern_dataset, '', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned\n",
    "\n",
    "df_dataset_idcontent['dataset_content'] = df_dataset_idcontent['dataset_content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Textual_Feature:\n",
    "    def __init__(self, checkpoint= 'allenai/scibert_scivocab_uncased'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def encode(self, paper_text):\n",
    "        tok_text = self.tokenizer(paper_text,\n",
    "                             truncation = True,\n",
    "                             max_length = 512, # before this guna 25 # before this guna 120\n",
    "                             padding = 'max_length',\n",
    "                             return_tensors='pt')\n",
    "        \n",
    "        if 'token_type_ids' in tok_text:\n",
    "            del tok_text['token_type_ids']\n",
    "        # with torch.no_grad():\n",
    "        #     outputs = self.lm(**tok_text)\n",
    "        # embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        return tok_text['input_ids'], tok_text['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\AppData\\Local\\Temp4\\ipykernel_2028\\2922747940.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_paper['abstract'] =  df_paper['abstract'].str.lower()\n",
      "C:\\Users\\Ammar\\AppData\\Local\\Temp4\\ipykernel_2028\\2922747940.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_paper['title'] =  df_paper['title'].str.lower()\n",
      "100%|██████████| 461/461 [00:00<00:00, 2030.55it/s]\n",
      "100%|██████████| 17397/17397 [00:14<00:00, 1188.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "textual_feature = Textual_Feature()\n",
    "df_paper['abstract'] =  df_paper['abstract'].str.lower()\n",
    "df_paper['title'] =  df_paper['title'].str.lower()\n",
    "paper_texts = df_paper['title'] + ' ' + df_paper['abstract']\n",
    "\n",
    "dataset_text = df_dataset_idcontent['dataset_content']\n",
    "\n",
    "\n",
    "token_dataset = dataset_text.progress_apply(lambda text: textual_feature.encode(text))\n",
    "token_paper = paper_texts.progress_apply(lambda text: textual_feature.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for dataset'''\n",
    "input_ids_list_dataset = [result[0] for result in token_dataset]\n",
    "attention_mask_list_dataset = [result[1] for result in token_dataset]\n",
    "\n",
    "input_ids_tensor_dataset = torch.cat(input_ids_list_dataset, dim=0)\n",
    "attention_mask_tensor_dataset = torch.cat(attention_mask_list_dataset, dim=0)\n",
    "\n",
    "'''for paper'''\n",
    "\n",
    "input_ids_list_paper = [result[0] for result in token_paper]\n",
    "attention_mask_list_paper = [result[1] for result in token_paper]\n",
    "\n",
    "input_ids_tensor_paper = torch.cat(input_ids_list_paper, dim=0)\n",
    "attention_mask_tensor_paper = torch.cat(attention_mask_list_paper, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     13\u001b[0m         input_ids_d \u001b[38;5;241m=\u001b[39m input_ids_tensor_dataset[dataset_id]\n\u001b[0;32m     14\u001b[0m         attention_mask_d \u001b[38;5;241m=\u001b[39m attention_mask_tensor_dataset[dataset_id]\n\u001b[0;32m     16\u001b[0m         row \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaper_id\u001b[39m\u001b[38;5;124m'\u001b[39m: paper_id,\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_id\u001b[39m\u001b[38;5;124m'\u001b[39m: dataset_id,\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(weight),\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids_p\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids_p: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_p\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_p\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_p: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_mask_p\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids_d\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids_d: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_d\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_d\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_d: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_mask_d\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m         }\n\u001b[0;32m     26\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_csv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor.py:966\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m--> 966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor_str.py:597\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    596\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 597\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    600\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    347\u001b[0m     )\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\anaconda3\\envs\\datafinder\\lib\\site-packages\\torch\\_tensor_str.py:129\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 129\u001b[0m     tensor_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloating_dtype:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m tensor_view:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = './datafinder/train_structural.txt'\n",
    "output_csv = './train.csv'\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        items = split(' ', line.strip())\n",
    "        paper_id = int(items[0])\n",
    "        dataset_id = int(items[1])\n",
    "        weight = items[2]\n",
    "        input_ids_p = input_ids_tensor_paper[paper_id]\n",
    "        attention_mask_p = attention_mask_tensor_paper[paper_id]\n",
    "        input_ids_d = input_ids_tensor_dataset[dataset_id]\n",
    "        attention_mask_d = attention_mask_tensor_dataset[dataset_id]\n",
    "\n",
    "        row = {\n",
    "            'paper_id': paper_id,\n",
    "            'dataset_id': dataset_id,\n",
    "            'weight': float(weight),\n",
    "            'input_ids_p': f'input_ids_p: {input_ids_p}',\n",
    "            'attention_mask_p': f'attention_mask_p: {attention_mask_p}',\n",
    "            'input_ids_d': f'input_ids_d: {input_ids_d}',\n",
    "            'attention_mask_d': f'attention_mask_d: {attention_mask_d}'\n",
    "        }\n",
    "\n",
    "        data.append(row)\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['paper_id', 'dataset_id', 'weight', 'input_ids_p', 'attention_mask_p', 'input_ids_d', 'attention_mask_d']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './datafinder/test_structural.txt'\n",
    "output_csv = './test.csv'\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        items = split(' ', line.strip())\n",
    "        paper_id = int(items[0])\n",
    "        dataset_id = int(items[1])\n",
    "        weight = items[2]\n",
    "        input_ids_p = input_ids_tensor_paper[paper_id]\n",
    "        attention_mask_p = attention_mask_tensor_paper[paper_id]\n",
    "        input_ids_d = input_ids_tensor_dataset[dataset_id]\n",
    "        attention_mask_d = attention_mask_tensor_dataset[dataset_id]\n",
    "\n",
    "        row = {\n",
    "            'paper_id': paper_id,\n",
    "            'dataset_id': dataset_id,\n",
    "            'weight': float(weight),\n",
    "            'input_ids_p': f'input_ids_p: {input_ids_p}',\n",
    "            'attention_mask_p': f'attention_mask_p: {attention_mask_p}',\n",
    "            'input_ids_d': f'input_ids_d: {input_ids_d}',\n",
    "            'attention_mask_d': f'attention_mask_d: {attention_mask_d}'\n",
    "        }\n",
    "\n",
    "        data.append(row)\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['paper_id', 'dataset_id', 'weight', 'input_ids_p', 'attention_mask_p', 'input_ids_d', 'attention_mask_d']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
